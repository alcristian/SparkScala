{"cells":[{"cell_type":"markdown","source":["# Operações Básicas com PySpark e Spark DataFrames"],"metadata":{}},{"cell_type":"markdown","source":["Após darmos os primeiros passos com o PySpark no Objeto de Aprendizagem anterior, vamos agora aplicar algumas técnicas básicas de manipulação de dados para nos familiarizarmos mais com a tecnologia antes de lidar com maiores volumes de dados.\n\nVamos prosseguir com o exemplo de disciplinas da especialização e enriquecê-lo com mais conteúdo. Ao final pedirei que vocês complementem nosso DataFrame com mais dados coletados de outras disciplinas para uma pequena atividade. Peço também um pouco de paciência com relação aos dados. No próximo Objeto de Aprendizagem passaremos a utilizar fontes de dados externas!"],"metadata":{}},{"cell_type":"markdown","source":["## Preparativos\n\nAssim como no notebook anterior, vamos iniciar carregando o módulo `pyspark.sql`, criando uma sessão local e montando nosso DataFrame."],"metadata":{}},{"cell_type":"code","source":["# Uso do Spark Dataframes no PySpark\nfrom pyspark.sql import *\n\n# Vamos trabalhar com o Spark localmente, sem o uso de um cluster.\nspark = SparkSession \\\n    .builder \\\n    .master(\"local[4]\") \\\n    .appName(\"Operações Básicas\") \\\n    .getOrCreate()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":4},{"cell_type":"code","source":["# Estrutura do nosso DataFrame\nDisciplina = Row(\"nome\", \"carga_horaria\")\n\n# Cada uma das disciplinas da especialização é criada como uma instância do registro Disciplina.\nd01 = Disciplina(\"Introdução a BigData e Analytics\", 36)\nd02 = Disciplina(\"Estatística aplicada\", 24)\nd03 = Disciplina(\"Visualização de dados e informação\", 24)\nd04 = Disciplina(\"Compartilhamento e segurança de dados\", 24)\nd05 = Disciplina(\"Introdução a Python e linguagem R\", 36)\nd06 = Disciplina(\"Machine Learning\", 24)\nd07 = Disciplina(\"Processamento de Alto Desempenho e Aplicações\", 24)\nd08 = Disciplina(\"Lidando com BigData: Apache Spark, Hadoop, MapReduce, Hive\", 24)\nd09 = Disciplina(\"Gerenciamento e Processamento de grande volume de dados\", 24)\nd10 = Disciplina(\"Internet das Coisas e Aplicações Distribuídas\", 24)\nd11 = Disciplina(\"Deep Learning\", 24)\nd12 = Disciplina(\"Business Intelligence e BigData\", 24)\nd13 = Disciplina(\"Atividades Integradoras\", 12)\nd14 = Disciplina(\"Preparação para Projeto Aplicado\", 36)\n\nespecializacao_bigdata_datascience = [d01, d02, d03, d04, d05, d06, d07, d08, d09, d10, d11, d12, d13, d14]\n\ndf_especializacao = spark.createDataFrame(especializacao_bigdata_datascience)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":5},{"cell_type":"markdown","source":["## Seleção de Colunas\n\nComo visto no texto base, há diferentes formas de selecionar colunas de um DataFrame. Hora de aplicar!"],"metadata":{}},{"cell_type":"code","source":["display(df_especializacao)\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>nome</th><th>carga_horaria</th></tr></thead><tbody><tr><td>Introdução a BigData e Analytics</td><td>36</td></tr><tr><td>Estatística aplicada</td><td>24</td></tr><tr><td>Visualização de dados e informação</td><td>24</td></tr><tr><td>Compartilhamento e segurança de dados</td><td>24</td></tr><tr><td>Introdução a Python e linguagem R</td><td>36</td></tr><tr><td>Machine Learning</td><td>24</td></tr><tr><td>Processamento de Alto Desempenho e Aplicações</td><td>24</td></tr><tr><td>Lidando com BigData: Apache Spark, Hadoop, MapReduce, Hive</td><td>24</td></tr><tr><td>Gerenciamento e Processamento de grande volume de dados</td><td>24</td></tr><tr><td>Internet das Coisas e Aplicações Distribuídas</td><td>24</td></tr><tr><td>Deep Learning</td><td>24</td></tr><tr><td>Business Intelligence e BigData</td><td>24</td></tr><tr><td>Atividades Integradoras</td><td>12</td></tr><tr><td>Preparação para Projeto Aplicado</td><td>36</td></tr></tbody></table></div>"]}}],"execution_count":7},{"cell_type":"markdown","source":["### Seleção das colunas com retorno de valor"],"metadata":{}},{"cell_type":"markdown","source":["#### Por meio de Indexação (formato Python)\n\nAs 3 formas abaixo retornarão um DataFrame somente com a coluna `nome`."],"metadata":{}},{"cell_type":"markdown","source":["##### Diretamente pelo nome da coluna"],"metadata":{}},{"cell_type":"code","source":["#df_especializacao.show()\ndf_especializacao[[\"nome\"]].show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------------+\n                nome|\n+--------------------+\nIntrodução a BigD...|\nEstatística aplicada|\nVisualização de d...|\nCompartilhamento ...|\nIntrodução a Pyth...|\n    Machine Learning|\nProcessamento de ...|\nLidando com BigDa...|\nGerenciamento e P...|\nInternet das Cois...|\n       Deep Learning|\nBusiness Intellig...|\nAtividades Integr...|\nPreparação para P...|\n+--------------------+\n\n</div>"]}}],"execution_count":11},{"cell_type":"markdown","source":["##### Utilizando a função `col`"],"metadata":{}},{"cell_type":"code","source":["## Mais um módulo para nossa coleção de módulos dominados!!\nfrom pyspark.sql.functions import *\n\ndf_especializacao[[col('nome')]].show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------------+\n                nome|\n+--------------------+\nIntrodução a BigD...|\nEstatística aplicada|\nVisualização de d...|\nCompartilhamento ...|\nIntrodução a Pyth...|\n    Machine Learning|\nProcessamento de ...|\nLidando com BigDa...|\nGerenciamento e P...|\nInternet das Cois...|\n       Deep Learning|\nBusiness Intellig...|\nAtividades Integr...|\nPreparação para P...|\n+--------------------+\n\n</div>"]}}],"execution_count":13},{"cell_type":"markdown","source":["##### Pela notação de ponto"],"metadata":{}},{"cell_type":"code","source":["df_especializacao[[df_especializacao.nome]].show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------------+\n                nome|\n+--------------------+\nIntrodução a BigD...|\nEstatística aplicada|\nVisualização de d...|\nCompartilhamento ...|\nIntrodução a Pyth...|\n    Machine Learning|\nProcessamento de ...|\nLidando com BigDa...|\nGerenciamento e P...|\nInternet das Cois...|\n       Deep Learning|\nBusiness Intellig...|\nAtividades Integr...|\nPreparação para P...|\n+--------------------+\n\n</div>"]}}],"execution_count":15},{"cell_type":"markdown","source":["#### Pelo método `select` (API Spark DataFrame)"],"metadata":{}},{"cell_type":"markdown","source":["As 3 formas abaixo retornarão um DataFrame somente com a coluna carga_horaria."],"metadata":{}},{"cell_type":"code","source":["# Diretamente pelo nome da coluna\ndf_especializacao.select('carga_horaria').show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-------------+\ncarga_horaria|\n+-------------+\n           36|\n           24|\n           24|\n           24|\n           36|\n           24|\n           24|\n           24|\n           24|\n           24|\n           24|\n           24|\n           12|\n           36|\n+-------------+\n\n</div>"]}}],"execution_count":18},{"cell_type":"code","source":["# Utilizando a função col\ndf_especializacao.select(col('carga_horaria')).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-------------+\ncarga_horaria|\n+-------------+\n           36|\n           24|\n           24|\n           24|\n           36|\n           24|\n           24|\n           24|\n           24|\n           24|\n           24|\n           24|\n           12|\n           36|\n+-------------+\n\n</div>"]}}],"execution_count":19},{"cell_type":"code","source":["# Pela notação de ponto\ndf_especializacao.select(df_especializacao.carga_horaria).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-------------+\ncarga_horaria|\n+-------------+\n           36|\n           24|\n           24|\n           24|\n           36|\n           24|\n           24|\n           24|\n           24|\n           24|\n           24|\n           24|\n           12|\n           36|\n+-------------+\n\n</div>"]}}],"execution_count":20},{"cell_type":"markdown","source":["### Referência ao objeto `Column`\n\nComo dito no texto base, a função `col` e a notação de ponto fazem referência ao objeto `Column` do DataFrame. Este objeto é necessário para uso em operações lógicas, para diferenciar os operadores lógicos da linguagem Python dos operadores lógicos existentes no Spark DataFrames/Spark SQL. Entraremos em maiores detalhes quando estudarmos a arquitetura do Apache Spark."],"metadata":{}},{"cell_type":"code","source":["type(df_especializacao.nome)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">12</span><span class=\"ansired\">]: </span>pyspark.sql.column.Column\n</div>"]}}],"execution_count":22},{"cell_type":"code","source":["type(col('nome'))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">13</span><span class=\"ansired\">]: </span>pyspark.sql.column.Column\n</div>"]}}],"execution_count":23},{"cell_type":"markdown","source":["Para fixar a diferença, vamos tentar usar o método `show` numa abordagem que retorna valor e numa abordagem que retorna o objeto `Column`:"],"metadata":{}},{"cell_type":"code","source":["# .show() em retorno de valor\ndf_especializacao[[df_especializacao.carga_horaria]].show(5)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-------------+\ncarga_horaria|\n+-------------+\n           36|\n           24|\n           24|\n           24|\n           36|\n+-------------+\nonly showing top 5 rows\n\n</div>"]}}],"execution_count":25},{"cell_type":"code","source":["# .show() em objeto Column. \n# Ocorre um erro do tipo TypeError alertando que não é possível chamar este método no objeto Column.\n\ntry:\n    df_especializacao.carga_horaria.show(5)\n\nexcept TypeError as err:\n    print(\"Erro: {}\".format(err))\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Erro: &apos;Column&apos; object is not callable\n</div>"]}}],"execution_count":26},{"cell_type":"markdown","source":["## Filtros"],"metadata":{}},{"cell_type":"markdown","source":["Vimos no texto base que os filtros removem registros que não correspondem aos critérios especificados. Nada melhor que um exemplo pra mostrar na prática o que isso significa. Das nossas experimentações anteriores já sabemos que as disciplinas possuem durações de 12, 24 ou 36 horas. \n\nO que fazer se quisermos visualizar somente aquelas com 36 horas? Aí que entram os filtros. Basta especificarmos um critério de carga horária igual a 36 horas, como demonstrado abaixo."],"metadata":{}},{"cell_type":"code","source":["df_especializacao[df_especializacao[\"carga_horaria\"] == 36].show(truncate=60)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---------------------------------+-------------+\n                             nome|carga_horaria|\n+---------------------------------+-------------+\n Introdução a BigData e Analytics|           36|\nIntrodução a Python e linguagem R|           36|\n Preparação para Projeto Aplicado|           36|\n+---------------------------------+-------------+\n\n</div>"]}}],"execution_count":29},{"cell_type":"markdown","source":["Falta só mais uma com essa carga horária 🙂\n\nE quantas possuem duração **menor** que 36 horas?"],"metadata":{}},{"cell_type":"code","source":["df_especializacao[df_especializacao[\"carga_horaria\"] < 36].show(truncate=60)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----------------------------------------------------------+-------------+\n                                                      nome|carga_horaria|\n+----------------------------------------------------------+-------------+\n                                      Estatística aplicada|           24|\n                        Visualização de dados e informação|           24|\n                     Compartilhamento e segurança de dados|           24|\n                                          Machine Learning|           24|\n             Processamento de Alto Desempenho e Aplicações|           24|\nLidando com BigData: Apache Spark, Hadoop, MapReduce, Hive|           24|\n   Gerenciamento e Processamento de grande volume de dados|           24|\n             Internet das Coisas e Aplicações Distribuídas|           24|\n                                             Deep Learning|           24|\n                           Business Intelligence e BigData|           24|\n                                   Atividades Integradoras|           12|\n+----------------------------------------------------------+-------------+\n\n</div>"]}}],"execution_count":31},{"cell_type":"markdown","source":["## Agregação"],"metadata":{}},{"cell_type":"markdown","source":["Aqui exploraremos algumas formas simples de agregação, que aprofundaremos nos materiais seguintes. Este primeiro exemplo abaixo parece bem auto-descritivo né? Significa agrupar por carga horária - criar nossos subconjuntos onde cada subconjunto concentra registros de mesma carga horária - e então contar a quantidade de registros por subconjunto."],"metadata":{}},{"cell_type":"code","source":["df_especializacao.groupBy(df_especializacao.carga_horaria).count().show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-------------+-----+\ncarga_horaria|count|\n+-------------+-----+\n           12|    1|\n           36|    3|\n           24|   10|\n+-------------+-----+\n\n</div>"]}}],"execution_count":34},{"cell_type":"markdown","source":["Uma forma diferente de agrupamento é colocar todo o DataFrame em um único subconjunto. Isso se faz necessário pois não temos como aplicar as operações de subconjuntos sem agrupamento. Abaixo vemos como calcular uma média de carga horária para toda a especialização."],"metadata":{}},{"cell_type":"code","source":["df_especializacao.groupBy().mean('carga_horaria').show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+------------------+\navg(carga_horaria)|\n+------------------+\n25.714285714285715|\n+------------------+\n\n</div>"]}}],"execution_count":36},{"cell_type":"markdown","source":["Para aplicar mais de uma operação de subconjuntos podemos listar todas elas dentro de uma operação de agregação (**`agg`**). Neste caso estamos tirando proveito do grupo criado para aplicar as três operações: média, mínimo e máximo. Isto é interessante pois operações de agregação em grandes volumes de dados podem ser computacionalmente custosas (e demoradas), então calcular tudo de uma vez faz mais sentido."],"metadata":{}},{"cell_type":"code","source":["df_especializacao.groupBy().agg(mean('carga_horaria'), min('carga_horaria'), max('carga_horaria')).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+------------------+------------------+------------------+\navg(carga_horaria)|min(carga_horaria)|max(carga_horaria)|\n+------------------+------------------+------------------+\n25.714285714285715|                12|                36|\n+------------------+------------------+------------------+\n\n</div>"]}}],"execution_count":38},{"cell_type":"markdown","source":["Finalizando... vocês devem ter percebido que os nomes das colunas após agregação ficam muito extensos e são ruins para referenciar em próximas operações. No exemplo abaixo mostro como atribuir novos nomes para o resultado de cada operação de agregação por meio do método **`alias`**."],"metadata":{}},{"cell_type":"code","source":["import pyspark.sql.functions as F\n\ndf_especializacao.groupBy() \\\n    .agg(mean('carga_horaria').alias('media'), \\\n         min('carga_horaria').alias('minimo'), \\\n         max('carga_horaria').alias('maximo')).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+------------------+------+------+\n             media|minimo|maximo|\n+------------------+------+------+\n25.714285714285715|    12|    36|\n+------------------+------+------+\n\n</div>"]}}],"execution_count":40},{"cell_type":"markdown","source":["#### Atividade 1\n\nAcesse a página de especializações da Unisinos [neste link](http://www.unisinos.br/pos#especializacao) e escolha uma especialização diferente desta de Big Data, Data Science e Data Analytics. Construa a sua estrutura curricular da mesma forma que fizemos no início deste Objeto de Aprendizagem até o ponto em que o DataFrame no Spark é criado. O nome do Spark DataFrame deve ser **`df_outra_especializacao`**.\n\nUtilize o bloco de código abaixo para criação deste DataFrame:"],"metadata":{}},{"cell_type":"code","source":["# Estrutura do nosso DataFrame\nDisciplina = Row(\"nome\", \"carga_horaria\")\n\n# Cada uma das disciplinas da especialização é criada como uma instância do registro Disciplina.\nd01 = Disciplina(\"Fundamentos e Metodologia da Bioética e da Ética Aplicada\", 36)\nd02 = Disciplina(\"Princípios e Filosofia da Bioética e da Ética Aplicada\", 24)\nd03 = Disciplina(\"Bioética e Saúde\", 24)\nd04 = Disciplina(\"Bioética: Sociedade, Meio Ambiente e Animais\", 24)\nd05 = Disciplina(\"História do surgimento e do desenvolvimento da bioética no contexto da ética\", 36)\nd06 = Disciplina(\"Lógica e metodologia científica aplicadas à ética e à bioética\", 24)\nd07 = Disciplina(\"Tópicos especiais em Ética em Pesquisa\", 24)\nd08 = Disciplina(\"Ética e pesquisa qualitativa e ética em pesquisa nas humanidades\", 24)\nd09 = Disciplina(\"Melhoramento humano, Neuroética e genética\", 24)\nd10 = Disciplina(\"Princípio e responsabilidade e o problema das futuras gerações\", 24)\nd11 = Disciplina(\"Comitês de Ética em Pesquisa e o consentimento informado em pesquisa\", 24)\nd12 = Disciplina(\"Seminário Bioética Clínica\", 24)\nd13 = Disciplina(\"Atividades Integradoras\", 12)\nd14 = Disciplina(\"Seminário de Bioética e Saúde Coletiva\", 31)\n\ndf_bioetica_especializacao = [d01, d02, d03, d04, d05, d06, d07, d08, d09, d10, d11, d12, d13, d14]\n\ndf_outra_especializacao = spark.createDataFrame(df_bioetica_especializacao)\n\ndf_outra_especializacao.show()\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------------+-------------+\n                nome|carga_horaria|\n+--------------------+-------------+\nFundamentos e Met...|           36|\nPrincípios e Filo...|           24|\n    Bioética e Saúde|           24|\nBioética: Socieda...|           24|\nHistória do surgi...|           36|\nLógica e metodolo...|           24|\nTópicos especiais...|           24|\nÉtica e pesquisa ...|           24|\nMelhoramento huma...|           24|\nPrincípio e respo...|           24|\nComitês de Ética ...|           24|\nSeminário Bioétic...|           24|\nAtividades Integr...|           12|\nSeminário de Bioé...|           31|\n+--------------------+-------------+\n\n</div>"]}}],"execution_count":42},{"cell_type":"markdown","source":["#### Atividade 2\n\nAgora que temos dois DataFrames representando duas especializações diferentes será importante diferenciar um do outro. Vamos utilizar o nome de cada especialização para possibilitar esta diferenciação.\n\nO código abaixo aplica uma operação de criação de nova coluna no nosso DataFrame da especialização em Big Data, Data Science e Data Analytics. Aproveitei para modificar o nome da coluna de nome da disciplina, pois agora temos dois nomes diferentes: da especialização e da disciplina."],"metadata":{}},{"cell_type":"code","source":["# A função lit() é necessária para indicar ao Spark que o conteúdo passado para ela será o valor da coluna criada. Você deve achar isso um exagero, e concordo. Más é assim mesmo =/\n\ndf_bd_ds_da = df_especializacao \\\n      .withColumn(\"nome_especializacao\", lit(\"Big Data, Data Science e Data Analytics\")) \\\n      .withColumnRenamed(\"nome\", \"nome_disciplina\")\n\ndf_bd_ds_da.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------------+-------------+--------------------+\n     nome_disciplina|carga_horaria| nome_especializacao|\n+--------------------+-------------+--------------------+\nIntrodução a BigD...|           36|Big Data, Data Sc...|\nEstatística aplicada|           24|Big Data, Data Sc...|\nVisualização de d...|           24|Big Data, Data Sc...|\nCompartilhamento ...|           24|Big Data, Data Sc...|\nIntrodução a Pyth...|           36|Big Data, Data Sc...|\n    Machine Learning|           24|Big Data, Data Sc...|\nProcessamento de ...|           24|Big Data, Data Sc...|\nLidando com BigDa...|           24|Big Data, Data Sc...|\nGerenciamento e P...|           24|Big Data, Data Sc...|\nInternet das Cois...|           24|Big Data, Data Sc...|\n       Deep Learning|           24|Big Data, Data Sc...|\nBusiness Intellig...|           24|Big Data, Data Sc...|\nAtividades Integr...|           12|Big Data, Data Sc...|\nPreparação para P...|           36|Big Data, Data Sc...|\n+--------------------+-------------+--------------------+\n\n</div>"]}}],"execution_count":44},{"cell_type":"markdown","source":["Sua atividade é criar a coluna no DataFrame da outra especialização a partir do **`df_outra_especializacao`** e aproveitar para renomear a coluna do nome da disciplina. O DataFrame resultante deve se chamar **`df_especializacao_criada`**:"],"metadata":{}},{"cell_type":"code","source":["#df_especializacao_criada = ...\ndf_outra_especializacao_bioetica = df_outra_especializacao \\\n      .withColumn(\"nome_especializacao\", lit(\"Bioetica e Etica Aplicada\")) \\\n      .withColumnRenamed(\"nome\", \"nome_disciplina\")\n\ndf_outra_especializacao_bioetica.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------------+-------------+--------------------+\n     nome_disciplina|carga_horaria| nome_especializacao|\n+--------------------+-------------+--------------------+\nFundamentos e Met...|           36|Bioetica e Etica ...|\nPrincípios e Filo...|           24|Bioetica e Etica ...|\n    Bioética e Saúde|           24|Bioetica e Etica ...|\nBioética: Socieda...|           24|Bioetica e Etica ...|\nHistória do surgi...|           36|Bioetica e Etica ...|\nLógica e metodolo...|           24|Bioetica e Etica ...|\nTópicos especiais...|           24|Bioetica e Etica ...|\nÉtica e pesquisa ...|           24|Bioetica e Etica ...|\nMelhoramento huma...|           24|Bioetica e Etica ...|\nPrincípio e respo...|           24|Bioetica e Etica ...|\nComitês de Ética ...|           24|Bioetica e Etica ...|\nSeminário Bioétic...|           24|Bioetica e Etica ...|\nAtividades Integr...|           12|Bioetica e Etica ...|\nSeminário de Bioé...|           31|Bioetica e Etica ...|\n+--------------------+-------------+--------------------+\n\n</div>"]}}],"execution_count":46},{"cell_type":"markdown","source":["#### Atividade 3\n\nCom as duas especializações batizadas, vamos fazer algo mais interessante: criar um DataFrame que combina as duas especializações! O Spark DataFrames fornece uma operação para isso, chamada de `unionAll`."],"metadata":{}},{"cell_type":"code","source":["df_especializacoes = df_bd_ds_da.unionAll(df_outra_especializacao_bioetica)\ndf_especializacoes.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------------+-------------+--------------------+\n     nome_disciplina|carga_horaria| nome_especializacao|\n+--------------------+-------------+--------------------+\nIntrodução a BigD...|           36|Big Data, Data Sc...|\nEstatística aplicada|           24|Big Data, Data Sc...|\nVisualização de d...|           24|Big Data, Data Sc...|\nCompartilhamento ...|           24|Big Data, Data Sc...|\nIntrodução a Pyth...|           36|Big Data, Data Sc...|\n    Machine Learning|           24|Big Data, Data Sc...|\nProcessamento de ...|           24|Big Data, Data Sc...|\nLidando com BigDa...|           24|Big Data, Data Sc...|\nGerenciamento e P...|           24|Big Data, Data Sc...|\nInternet das Cois...|           24|Big Data, Data Sc...|\n       Deep Learning|           24|Big Data, Data Sc...|\nBusiness Intellig...|           24|Big Data, Data Sc...|\nAtividades Integr...|           12|Big Data, Data Sc...|\nPreparação para P...|           36|Big Data, Data Sc...|\nFundamentos e Met...|           36|Bioetica e Etica ...|\nPrincípios e Filo...|           24|Bioetica e Etica ...|\n    Bioética e Saúde|           24|Bioetica e Etica ...|\nBioética: Socieda...|           24|Bioetica e Etica ...|\nHistória do surgi...|           36|Bioetica e Etica ...|\nLógica e metodolo...|           24|Bioetica e Etica ...|\n+--------------------+-------------+--------------------+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":48},{"cell_type":"markdown","source":["Utilizando nosso novo DataFrame de duas especializações, responda às seguintes questões usando as operações de filtro e agregações estudadas até aqui. Não esqueça de utilizar a operação `show()` ou a função `display()` para mostrar o resultado!"],"metadata":{}},{"cell_type":"markdown","source":["1- Quantas disciplinas em cada especialização?"],"metadata":{}},{"cell_type":"code","source":["## seu código aqui:\ndf_especializacoes.groupBy(df_especializacoes.nome_especializacao).count().show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------------+-----+\n nome_especializacao|count|\n+--------------------+-----+\nBig Data, Data Sc...|   14|\nBioetica e Etica ...|   14|\n+--------------------+-----+\n\n</div>"]}}],"execution_count":51},{"cell_type":"markdown","source":["2- Qual das especializações possui mais disciplinas de 36h?"],"metadata":{}},{"cell_type":"code","source":["## seu código aqui:\n##df_especializacao[[col('nome')]]\ndf_count_esp = df_especializacoes[df_especializacoes[\"carga_horaria\"] == 36].groupBy(df_especializacoes.nome_especializacao).count()\ndf_count_esp.show()\ndf_res = df_count_esp[['nome_especializacao','count']].groupBy().max('count')\n#df_res[['max(count)']].show()\n\nv = df_count_esp[['nome_especializacao','count']].groupBy().max('count').collect()\n\nprint(v)\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------------+-----+\n nome_especializacao|count|\n+--------------------+-----+\nBig Data, Data Sc...|    3|\nBioetica e Etica ...|    2|\n+--------------------+-----+\n\n[Row(max(count)=3)]\n</div>"]}}],"execution_count":53},{"cell_type":"markdown","source":["3- Qual a média de carga horária de cada especialização?"],"metadata":{}},{"cell_type":"code","source":["## seu código aqui:\n\n#df_especializacoes.show()\n\ndf_especializacoes.groupBy(df_especializacoes.nome_especializacao).agg(mean('carga_horaria')).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------------+------------------+\n nome_especializacao|avg(carga_horaria)|\n+--------------------+------------------+\nBig Data, Data Sc...|25.714285714285715|\nBioetica e Etica ...|25.357142857142858|\n+--------------------+------------------+\n\n</div>"]}}],"execution_count":55},{"cell_type":"markdown","source":["4- Existe alguma disciplina com mesmo nome nas duas especializações? Liste o nome das disciplinas que se repetirem. Mesmo que não exista repetição, o DataFrame resultante deve retornar a coluna `nome_disciplina`.\n\n**Dica**: Use count(), filter() e select() para isso."],"metadata":{}},{"cell_type":"code","source":["## seu código aqui:\n#df_especializacoes.select('nome_disciplina').show()\ndf_refine = df_especializacoes.groupBy(df_especializacoes.nome_disciplina).count()\ndf_refine2 = df_refine[df_refine[\"count\"] >1]\ndf_refine2.show()\n\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------------+-----+\n     nome_disciplina|count|\n+--------------------+-----+\nAtividades Integr...|    2|\n+--------------------+-----+\n\n</div>"]}}],"execution_count":57},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":58}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"version":"3.7.2","nbconvert_exporter":"python","file_extension":".py"},"name":"operacoes_basicas","notebookId":712294970661258},"nbformat":4,"nbformat_minor":0}
